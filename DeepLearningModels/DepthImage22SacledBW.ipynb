{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code is for combine depth image paths and scale-based body weights information together and generate the csv file.  \n",
        "Revised code is for ARC specifically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "rootdir = \"UrRootFolder\"\n",
        "DAY = \"T1\"\n",
        "DAY_folder = rootdir + DAY\n",
        "file_path = \"UrScaleBWFolder\"\n",
        "\n",
        "if DAY == \"T1\":\n",
        "    bw_csv = \"ScaleBW.xlsx\"\n",
        "    bw_csv_path = file_path + bw_csv\n",
        "    print(bw_csv_path)\n",
        "\n",
        "bw_df = pd.read_excel(bw_csv_path) \n",
        "rowss = []\n",
        "DAY_folder = DAY_folder + \"/CSV_depth\"\n",
        "for pen in os.listdir(DAY_folder):\n",
        "  if pen.startswith(\"pen\"):\n",
        "        print(\"Now is running pen number\", pen)\n",
        "        dep_folder = DAY_folder + \"/\" + pen + \"/CSV_depth/\"\n",
        "        for bag_id in os.listdir(dep_folder):\n",
        "            depthdir = dep_folder + bag_id + \"/\"\n",
        "            images_per_bag = os.listdir(depthdir)\n",
        "            rows = []\n",
        "            try:\n",
        "              weight_per_bag = bw_df[\"Weight (gr)\"][bw_df[\"Top\"] == bag_id + \".bag\"].values[0]/1000\n",
        "            except IndexError:\n",
        "              continue\n",
        "            \n",
        "            for i, image_path in enumerate(images_per_bag):\n",
        "                row = [depthdir+image_path, pen, bag_id, weight_per_bag]\n",
        "                rows.append(row)\n",
        "            rowss.append(rows)\n",
        "  else:\n",
        "        continue\n",
        "  \n",
        "col_vals = ['FilePath', 'Pen', \"Bag_ID\",'Weights']\n",
        "labelled_depth = pd.concat(pd.DataFrame(rowss[i], columns=col_vals) for i in range(len(rowss)))\n",
        "labelled_depth = labelled_depth.dropna(axis=0)\n",
        "labelled_depth.to_csv(\"UrFolder/labelled_depth_\" + DAY + \".csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add CV info into labelled_depth.csv files For CV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def train_test_split(visit):\n",
        "    # Load dataframes\n",
        "    df1 = pd.read_csv(\"../labelled_depth_0718.csv\")\n",
        "    df2 = pd.read_csv(\"../labelled_depth_0801.csv\")\n",
        "    df3 = pd.read_csv(\"../labelled_depth_0815.csv\")\n",
        "    df4 = pd.read_csv(\"../labelled_depth_0829.csv\")\n",
        "    df5 = pd.read_csv(\"../labelled_depth_0912.csv\")\n",
        "    df6 = pd.read_csv(\"../labelled_depth_0927.csv\")\n",
        "\n",
        "    # Add 'Visit' column to each dataframe\n",
        "    df1['Visit'] = '0718'\n",
        "    df2['Visit'] = '0801'\n",
        "    df3['Visit'] = '0815'\n",
        "    df4['Visit'] = '0829'\n",
        "    df5['Visit'] = '0912'\n",
        "    df6['Visit'] = '0927'\n",
        "\n",
        "    # Select dataframe based on visit value\n",
        "    if visit == \"0718\":\n",
        "        labelled_depth = df1\n",
        "    elif visit == \"0801\":\n",
        "        labelled_depth = df2\n",
        "    elif visit == \"0815\":\n",
        "        labelled_depth = df3\n",
        "    elif visit == \"0829\":\n",
        "        labelled_depth = df4\n",
        "    elif visit == \"0912\":\n",
        "        labelled_depth = df5\n",
        "    elif visit == \"0927\":\n",
        "        labelled_depth = df6\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid visit value: {visit}\")\n",
        "\n",
        "    # Assign visit value to the dataframe\n",
        "    labelled_depth['Visit'] = str(visit)\n",
        "\n",
        "    # Calculate number of unique pigs (assuming Bag_ID is your pig identifier)\n",
        "    pig_n = np.unique(labelled_depth['Bag_ID']).shape[0]\n",
        "    seed=42\n",
        "    for rate in [0.75, 0.5, 0.25]:\n",
        "        # Set random seed\n",
        "        random.seed(seed)\n",
        "        cv_name = \"CrossValidation\"+str(rate)\n",
        "        # Initialize CrossValidation column with 'test'\n",
        "        labelled_depth[cv_name] = 'test'\n",
        "        train_bag_id = random.sample(list(np.unique(labelled_depth[\"Bag_ID\"])), int(pig_n * rate))\n",
        "        labelled_depth.loc[labelled_depth[\"Bag_ID\"].isin(train_bag_id), cv_name] = 'train'\n",
        "\n",
        "    # Save dataframe to CSV\n",
        "    labelled_depth.to_csv(f'../labelled_depth_{visit}.csv', index=False)\n",
        "\n",
        "\n",
        "# Call train_test_split for each visit\n",
        "for visit in ['0829']:\n",
        "    train_test_split(visit=visit)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
